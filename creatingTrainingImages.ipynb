{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "896ee4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbfd59b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Variables\n",
    "WIDTH = 1600\n",
    "HEIGHT = 900\n",
    "ORANGE_BACKGROUND = [12, 255, 255]\n",
    "ROOT_DIR = os.path.abspath(\"./\")\n",
    "IMGS_DIR = os.path.join(ROOT_DIR, \"Img\")\n",
    "f = open('./Img/annotations.json', 'r')\n",
    "annotations = json.load(f)\n",
    "orange_signs_list = os.listdir('./Img/RawOrangeSignImgs/')\n",
    "coco_imgs_list = os.listdir('./coco_dataset/chosenImages')\n",
    "daily_templates_list = os.listdir('./Img/Templates/Daily')\n",
    "frequent_templates_list = os.listdir('./Img/Templates/Frequent')\n",
    "uncommom_templates_list = os.listdir('./Img/Templates/Uncommon') \n",
    "# templates_list = [(daily_templates_list, frequent_templates_list, \n",
    "#                    uncommom_templates_list)]\n",
    "templates_list = orange_signs_list\n",
    "\n",
    "#Reduce the quantity to test the program\n",
    "coco_imgs_list = coco_imgs_list[:5000]\n",
    "\n",
    "# Total number of orange templates of signs\n",
    "orange_sings_list_length = len(orange_signs_list)  \n",
    "# Total number of templates of signs after categorized by frequency: Daily, Frequent, Uncommon\n",
    "dfu_total_length = len(daily_templates_list) + len(frequent_templates_list) + len(uncommom_templates_list)\n",
    "# The length must be equal, and ideally all names that are present in the orange signs list must be present in one of the three categories of templates\n",
    "assert orange_sings_list_length == dfu_total_length "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fadf6087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyErosion(mask):\n",
    "    '''\n",
    "    Apply Erosion to the mask.\n",
    "    -Erosion makes the mask smaller and removes noise.\n",
    "    :param mask: Mask to be eroded.\n",
    "    :return: Eroded mask.   \n",
    "    ''' \n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    mask = cv2.erode(mask, kernel, iterations=1)\n",
    "    return mask\n",
    "\n",
    "def getContours(mask):\n",
    "    '''\n",
    "    Uses OpenCV to find the contours of the mask.\n",
    "    To be a valid contour, it must have an area of at least 600pxÂ².\n",
    "    :param mask: Mask to be used to find contours.\n",
    "    :return: List of valid contours. \n",
    "    '''\n",
    "    valid_contours_list = []\n",
    "    contours, hierarchy = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for c in contours:\n",
    "        area = cv2.contourArea(c)\n",
    "        if area < 600:\n",
    "            continue\n",
    "        valid_contours_list.append(c)\n",
    "    return valid_contours_list\n",
    "\n",
    "def createMask(img):\n",
    "    '''\n",
    "    Creates a mask from the image.\n",
    "    In this project the image is a sign with a orange background.\n",
    "    :param img: Image to be used to create the mask.\n",
    "    :return: Mask created from the image.\n",
    "    '''\n",
    "    hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)  #Convert img from BGR to HSV\n",
    "    # print(\"HSV Img Shape: \", hsv_img.shape)\n",
    "\n",
    "    lower_limit = np.array(ORANGE_BACKGROUND) #Background HSV Color to create mask\n",
    "    upper_limit = np.array(ORANGE_BACKGROUND) #Background HSV Color to create mask\n",
    "\n",
    "    mask = cv2.inRange(hsv_img, lower_limit, upper_limit) #Select Orange area\n",
    "    mask_inv = cv2.bitwise_not(mask)   #Invert mask (deselect orang area) and select sign area       \n",
    "    mask_inv = applyErosion(mask_inv)       #Erode the mask to remove noise\n",
    "    #print(\"Mask-Inv Shape:\" + mask_inv.shape)  #should be (h, w, 3)\n",
    "    \n",
    "    return mask_inv\n",
    "\n",
    "def randomResize(img):\n",
    "    '''\n",
    "    Resizes the image to a random size.\n",
    "    :param img: Image to be resized.\n",
    "    :return: Resized image.\n",
    "    '''\n",
    "    random_scale = random.uniform(0.4, 1.1)\n",
    "    width, height = int(img.shape[1] * random_scale), int(img.shape[0] * random_scale)\n",
    "    img = cv2.resize(img, (width, height), interpolation=cv2.INTER_AREA)\n",
    "    return img\n",
    "\n",
    "\n",
    "def createTemplate(orange_signs_list):\n",
    "    '''\n",
    "    Creates a template for every orange sign from input list. \n",
    "    And saves it in a dictionary.\n",
    "    :param orange_signs_list: List of orange signs loaded from ./Img/RawOriginSign.\n",
    "    :return template_dict: Dictionary with the templates for each orange sign.\n",
    "    \n",
    "    template_dict = { sign_type1: [(sing_number, sign_rgba, contours_list)]\n",
    "                      sign_type2: [(sing_number, sign_rgba, contours_list), \n",
    "                                   (sing_number, sign_rgba, contours_list)]\n",
    "                      ...}),\n",
    "    '''\n",
    "    templates_dict = {}\n",
    "    for name in orange_signs_list:\n",
    "        name = name[:-4:]               # remove .jpg\n",
    "        sign_type = name[:-4:]          # select the sign type\n",
    "        sign_number = name[-4::]        # select the number of this sign type\n",
    "        img = cv2.imread(f'./Img/RawOrangeSignImgs/{sign_type + sign_number}.jpg')\n",
    "        img = randomResize(img)\n",
    "        # cv2.imshow(\"Img\", img)\n",
    "        # print('Img Shape:', img.shape)     \n",
    "\n",
    "        mask = createMask(img)\n",
    "        contours_list = getContours(mask) #Needed to the annotations\n",
    "\n",
    "        ## Using mask to select orange area and cut it from img, creating a transparent sign template\n",
    "        sign = cv2.bitwise_and(img, img, mask= mask)\n",
    "        ## Convert to RGBA (RGB with Alpha Channel)\n",
    "        sign_rgba = cv2.cvtColor(sign, cv2.COLOR_BGR2BGRA)\n",
    "        sign_rgba[:,:,3] = mask     #Add mask to alpha channel\n",
    "\n",
    "        ## Add new tuple to dictionary if it doesn't exist\n",
    "        if not templates_dict.get(sign_type):  \n",
    "            templates_dict[sign_type] = [(sign_number, sign_rgba, contours_list)]\n",
    "        ## The tuples contains the sign number (_XXX), sign image -> RGBA: (XXX, XXX, 4)) \n",
    "        # and contours list [shape: (n, 1, 2)]]                                 \n",
    "        else: \n",
    "            templates_dict[sign_type].append((sign_number, sign_rgba, contours_list))\n",
    "    \n",
    "    return templates_dict\n",
    "        \n",
    "templates_dict = createTemplate(orange_signs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac3ada86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['A-10a', 'A-10b', 'A-11a', 'A-11b', 'A-12', 'A-13a', 'A-13b', 'A-14', 'A-15', 'A-16', 'A-17', 'A-18', 'A-19', 'A-1a', 'A-1b', 'A-20a', 'A-20b', 'A-21a', 'A-21b', 'A-21c', 'A-21d', 'A-21e', 'A-22', 'A-23', 'A-24', 'A-25', 'A-26a', 'A-26b', 'A-27', 'A-28', 'A-29', 'A-2a', 'A-2b', 'A-30a', 'A-30b', 'A-30c', 'A-31', 'A-32a', 'A-32b', 'A-33a', 'A-33b', 'A-34', 'A-35', 'A-36', 'A-37', 'A-38', 'A-39', 'A-3a', 'A-3b', 'A-40', 'A-41', 'A-42a', 'A-42b', 'A-42c', 'A-43', 'A-44', 'A-45', 'A-46', 'A-47', 'A-48', 'A-4a', 'A-4b', 'A-5a', 'A-5b', 'A-6', 'A-7a', 'A-7b', 'A-8', 'A-9', 'A-IC', 'A-SEA', 'I-E', 'I-IK', 'I-I', 'I-O', 'I-SA01', 'I-SA02', 'I-SA06', 'I-SA07', 'I-SA08', 'I-SA09', 'I-SA10', 'I-SA11', 'I-SA12', 'I-SA13', 'I-SA14', 'I-SA18', 'I-SA19', 'I-SA20', 'I-SA21', 'I-SA24', 'I-SA26', 'I-SA', 'O-FE', 'O-MA', 'O-MP', 'O-OA15', 'O-OA17', 'O-OA18', 'O-OA19', 'O-OA21a', 'O-OA21b', 'O-OA21c', 'O-OA24', 'O-OA25', 'O-OA27', 'O-OA28', 'O-OA29', 'O-OA37', 'O-OA38', 'O-OA42a', 'O-O', 'O-SC', 'R-10', 'R-11', 'R-12', 'R-13', 'R-14', 'R-15', 'R-16', 'R-17', 'R-18', 'R-19', 'R-1', 'R-20', 'R-21', 'R-22', 'R-23', 'R-24a', 'R-24b', 'R-25a', 'R-25b', 'R-25c', 'R-25d', 'R-26', 'R-27', 'R-28', 'R-29', 'R-2', 'R-30', 'R-31', 'R-32', 'R-33', 'R-34', 'R-35a', 'R-35b', 'R-36a', 'R-36b', 'R-37', 'R-38', 'R-39', 'R-3', 'R-40', 'R-4a', 'R-4b', 'R-5a', 'R-5b', 'R-6a', 'R-6b', 'R-6c', 'R-7', 'R-8a', 'R-8b', 'R-9', 'R-IC', 'T-I', 'T-SAU01', 'T-SAU02', 'T-SAU03', 'T-SAU04', 'T-SAU05', 'T-SAU06', 'T-SAU07', 'T-SAU08', 'T-SAU09', 'T-SAU10', 'T-SAU11', 'T-SAU12', 'T-SAU13', 'T-SAU14', 'T-SAU15', 'T-SAU19', 'T-SAU20', 'T-SAU21', 'T-SAU22', 'T-SAU23', 'T-SAU24', 'T-SAU25', 'T-SAU26', 'T-TAD01', 'T-TAD02', 'T-TAD03', 'T-TAD04', 'T-TAD05', 'T-TAD06', 'T-TAD07', 'T-TAD08', 'T-TAD09', 'T-TAD10', 'T-TAD11', 'T-TAD12', 'T-TAD13', 'T-TAD14', 'T-TAD15', 'T-TAD16', 'T-TAR01', 'T-TAR02', 'T-TAR03', 'T-TAR04', 'T-TAR05', 'T-TAR06', 'T-TAR07', 'T-THC01', 'T-THC02', 'T-THC03', 'T-THC04', 'T-THC05', 'T-THC06', 'T-THC07', 'T-THC08', 'T-THC09', 'T-THC10', 'T-THC11', 'T-TIT01', 'T-TIT02', 'T-TIT03', 'T-TIT04', 'T-TIT05', 'T-TIT06', 'T-TIT07', 'T-TIT08', 'T-TIT09', 'T-TIT10', 'T-TNA01', 'T-TNA02', 'T-TNA03', 'T-TNA04', 'T-TNA05', 'T-TNA06', 'T-TNA07', 'T-TNA08', 'T-TNA09'])\n",
      "242\n"
     ]
    }
   ],
   "source": [
    "print(templates_dict.keys())\n",
    "print(len(templates_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e9ebc380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total errors: 107.0\n"
     ]
    }
   ],
   "source": [
    "SAVE = True\n",
    "ANNOTATIONS = True\n",
    "DRAW_CONTOURS = False\n",
    "avaiable_templates = set(orange_signs_list)\n",
    "\n",
    "def addBlur(img):\n",
    "    '''\n",
    "    Adds a blur to the image.\n",
    "    :param img: Image to be blurred.\n",
    "    :return: Blurred image.\n",
    "    '''\n",
    "    kernel = np.ones((5,5), np.float32)/25  #Blur kernel with a size of 5x5 and a factor of 1/25 (default)\n",
    "    img = cv2.filter2D(img, -1, kernel)     #Blur image using kernel\n",
    "    return img\n",
    "\n",
    "def checkIntervals(a, b, c, d):\n",
    "    '''\n",
    "    Checks if a < b and c < d.\n",
    "    :param a: First interval start.\n",
    "    :param b: First interval end.\n",
    "    :param c: Second interval start.\n",
    "    :param d: Second interval end.\n",
    "    :return: True if b-a and d-c are greater than 0, False otherwise.\n",
    "    '''\n",
    "    if a < b and c < d:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def chooseOffset(i, temp_w, temp_h):\n",
    "    '''\n",
    "    Depending on the quadrant we are drawing the template, we choose a different random offset.\n",
    "    :param i: Quadrant we are drawing the template.\n",
    "    :param temp_w: Template width.\n",
    "    :param temp_h: Template height.\n",
    "    :return: Random offset for the specific quadrant.\n",
    "    '''\n",
    "    if i == 0:\n",
    "        valid_intervals = checkIntervals(temp_w, WIDTH/2-temp_w, temp_h, HEIGHT/2-temp_h)\n",
    "        # Change these to change the position of first sign\n",
    "        if valid_intervals:\n",
    "            x_offset, y_offset= np.random.randint(temp_w, WIDTH/2-temp_w), np.random.randint(temp_h, HEIGHT/2-temp_h)     \n",
    "        else:\n",
    "            x_offset, y_offset= np.random.randint(5, temp_w), np.random.randint(5, temp_h)     \n",
    "    elif i == 1:\n",
    "        valid_intervals = checkIntervals(WIDTH/2+temp_w, WIDTH - temp_w, temp_h, HEIGHT/2-temp_h)\n",
    "        # Change these to change the position of second sign\n",
    "        if valid_intervals:\n",
    "            x_offset, y_offset= np.random.randint(WIDTH/2 + temp_w, WIDTH - temp_w), np.random.randint(temp_h, HEIGHT/2-temp_h)     \n",
    "        else:\n",
    "            x_offset, y_offset= np.random.randint(WIDTH/2, WIDTH/2 + temp_w), np.random.randint(10, temp_h)     \n",
    "    elif i == 2:\n",
    "        valid_intervals = checkIntervals(temp_w, WIDTH/2 - temp_w, HEIGHT/2+temp_h, HEIGHT - temp_h)\n",
    "        # Change these to change the position of third sign\n",
    "        if valid_intervals:\n",
    "            x_offset, y_offset= np.random.randint(temp_w, WIDTH/2 - temp_w), np.random.randint(HEIGHT/2 + temp_h, HEIGHT - temp_h)\n",
    "        else:\n",
    "            x_offset, y_offset= np.random.randint(10, temp_w), np.random.randint(HEIGHT/2 + 10, HEIGHT/2 + temp_h)\n",
    "    else:\n",
    "        valid_intervals = checkIntervals(WIDTH/2+temp_w, WIDTH - temp_w, HEIGHT/2+temp_h, HEIGHT - temp_h)\n",
    "        # Change these to change the position of fourth sign\n",
    "        if valid_intervals:\n",
    "            x_offset, y_offset= np.random.randint(WIDTH/2+temp_w, WIDTH - temp_h), np.random.randint(HEIGHT/2+temp_h, HEIGHT-temp_h)     \n",
    "        else:\n",
    "            x_offset, y_offset= np.random.randint(WIDTH/2+10, WIDTH/2 + temp_w), np.random.randint(HEIGHT/2+10, HEIGHT/2 + temp_h)\n",
    "\n",
    "    return x_offset, y_offset\n",
    "\n",
    "\n",
    "def addOffsetToContour(x_offset, y_offset, contours): \n",
    "    '''\n",
    "    Add offset to contours according to the position that we paste the sign template.\n",
    "    :param x_offset: X offset.\n",
    "    :param y_offset: Y offset.\n",
    "    :param contours: Contours to be offset.\n",
    "    :return: Offsetted contours.\n",
    "    '''\n",
    "    for contour in contours:\n",
    "        new_contour = contour + (x_offset, y_offset)\n",
    "    return new_contour\n",
    "\n",
    "\n",
    "def createPointsFromContours(contours):\n",
    "    '''\n",
    "    Create list of points_x and points_y from contours, to be used for create JSON object for annotations.\n",
    "    :param contours: Contours that gonna be used to extract values for points_x and points_y.\n",
    "    :return: Two lists: points_x, points_y\n",
    "    '''\n",
    "    points_x = []\n",
    "    points_y = []\n",
    "    for contour in contours:\n",
    "        for point in contour:\n",
    "            points_x.append(point[0])\n",
    "            points_y.append(point[1])\n",
    "    assert len(points_x) == len(points_y), \"Error: points_x and points_y have different length\"    \n",
    "    return points_x, points_y\n",
    "\n",
    "def selectTemplates(numberOfSigns):\n",
    "    global avaiable_templates\n",
    "    chosen_list = []\n",
    "\n",
    "    while numberOfSigns > 0:\n",
    "        if len(avaiable_templates) == 0:\n",
    "            avaiable_templates = set(orange_signs_list)\n",
    "        #print(len(avaiable_templates))\n",
    "        chosen = random.choice(list(avaiable_templates))\n",
    "        avaiable_templates.remove(chosen)\n",
    "        chosen = chosen[:-4:]\n",
    "        chosen_list.append(chosen)\n",
    "        numberOfSigns -= 1\n",
    "        \n",
    "        ## Choose random sign from daily, frequent or uncommom list, with weights of 0.5:0.3:0.2\n",
    "        # chosen_frequency = random.choices(\n",
    "        #     [daily_templates_list, frequent_templates_list, uncommom_templates_list], \n",
    "        #     weights=[0.5, 0.3, 0.2], k=1)[0]\n",
    "        ## Choose random sign from chosen list\n",
    "        # chosen_sign = random.choices(chosen_frequency, k=1)[0] \n",
    "        # chosen_sign = chosen_sign[:-4:] # remove .jpg\n",
    "        \n",
    "    return chosen_list\n",
    "\n",
    "\n",
    "\n",
    "def pasteTemplateIntoCocoImage(coco_img, templates_list, templates_dict):\n",
    "    '''\n",
    "    Uses arbitrary image `coco_img` and pastes beteen 1 and 4 templates of random signs into it.\n",
    "    :param coco_img: Image to be used to paste templates.\n",
    "    :param templates_list: List of templates with 3 sublists, each of then containnig signs of one these categories:\n",
    "        Daily: Signs that are the most for the day user.\n",
    "        Frequent: Signs that everybody have seen at least once.\n",
    "        Uncommom: Signs that probably aren't used often and fewer people know about them.\n",
    "    :param templates_dict: Dictionary with the templates and contours for each sign.\n",
    "    :return coco_img, countErrors, regions: Image with templates pasted, number of errors when pasting and regions to be used for annotations.\n",
    "    '''\n",
    "    countErrors = 0\n",
    "    numberOfSigns = np.random.randint(1, 5) # Random number of signs to be placed in the image [1, 4]\n",
    "    \n",
    "    ## Unpack templates_list\n",
    "    #daily_templates_list, frequent_templates_list, uncommom_templates_list = templates_list[0] \n",
    "    \n",
    "    chosen_list = [] # List to save 1 to 4 signs templates to paste in the image\n",
    "    regions = [] # List to save object of regions to be used for annotations\n",
    "\n",
    "    chosen_list = selectTemplates(numberOfSigns)\n",
    "      \n",
    "    \n",
    "    for i, sign in enumerate(chosen_list):\n",
    "        sign_number = int(sign[-3::]) # select the number of this sign type\n",
    "        sign_type = sign[:-4:] # select the sign type\n",
    "\n",
    "        template_tuple = templates_dict[sign_type][sign_number] # get the template tuple for this sign\n",
    "        template = template_tuple[1] # get the template image\n",
    "        temp_h, temp_w, _ = template.shape # template height and width\n",
    "        # print(template.shape)\n",
    "        \n",
    "        ## Choose offset for the chosen sign template\n",
    "        x_offset, y_offset = chooseOffset(i, temp_w, temp_h) \n",
    "        \n",
    "        ## Using the offset to drag the image down and to the right    \n",
    "        y1, y2 = y_offset, y_offset + template.shape[0]\n",
    "        x1, x2 = x_offset, x_offset + template.shape[1]\n",
    "\n",
    "        alpha_s = template[:, :, 3] / 255.0 # get the alpha channel of the template\n",
    "        alpha_l = 1.0 - alpha_s  # alpha_l is the alpha of the background of the template\n",
    "        \n",
    "        for c in range(0, 3):\n",
    "            try:\n",
    "                ## paste the template on the image\n",
    "                coco_img[y1:y2, x1:x2, c] = (alpha_s * template[:, :, c] +\n",
    "                                    alpha_l * coco_img[y1:y2, x1:x2, c])   \n",
    "                ## Add offset to contours\n",
    "                template_countour = addOffsetToContour(x_offset, y_offset, template_tuple[2])  \n",
    "\n",
    "                if DRAW_CONTOURS:\n",
    "                    ## Draw contours on the images to check if positions are correct\n",
    "                    cv2.drawContours(coco_img, [template_countour], -1, (0, 255, 0), 3) \n",
    "                \n",
    "                ## Create points_x and points_y from contours for annotations    \n",
    "                points_x, points_y = createPointsFromContours(template_countour)    \n",
    "\n",
    "                annot_obj = {           # Create object to convert for JSON annotations\n",
    "                    \"shape_attributes\": {\n",
    "                        \"name\": \"polygon\",\n",
    "                        \"all_points_x\": points_x,\n",
    "                        \"all_points_y\": points_y\n",
    "                    },\n",
    "                    \"region_attributes\": \n",
    "                        {\n",
    "                            \"class\": sign_type\n",
    "                        }\n",
    "                }\n",
    "                regions.append(annot_obj) # Add JSON object to regions list\n",
    "            except:\n",
    "                countErrors+= 1 # if the template is bigger than the image, the program will crash\n",
    "                #print(f\"Error pasting template {sign_type}_{sign_number} into image\")\n",
    "                continue  \n",
    "        \n",
    "    return coco_img, countErrors, regions\n",
    "\n",
    "def createSampleImages(templates_dict, coco_imgs_list, templates_list, blurry):\n",
    "    '''\n",
    "    Creates artificial images with templates of signs pasted in them.\n",
    "    :param templates_dict: Dictionary with the templates and contours for each sign.\n",
    "    :param coco_imgs_list: List of images to be used to paste templates.\n",
    "    :param templates_list: List of templates with 3 sublists, each of then containnig signs of one these categories:\n",
    "        Daily: Signs that are the most for the day user.\n",
    "        Frequent: Signs that everybody have seen at least once.\n",
    "        Uncommom: Signs that probably aren't used often and fewer people know about them.\n",
    "    :param blurry: Boolean variable to determine if the images will be blurred or not.\n",
    "    :return: Object with annotations for all images generated.\n",
    "    '''\n",
    "    img_list = []\n",
    "    annot_obj = {}     # Create empty object to save annotations\n",
    "    totalErrors = 0    # Count Errors when trying to paste the template into the image\n",
    "\n",
    "\n",
    "    \n",
    "    for name in coco_imgs_list:\n",
    "        name = name[:-4:]       # remove .jpg\n",
    "        coco_img = cv2.imread(f'./coco_dataset/chosenImages/{name}.jpg')\n",
    "        ## Eliminate images with height greater than width (portraits)   \n",
    "        if(coco_img.shape[0] > coco_img.shape[1]):    \n",
    "            continue\n",
    "\n",
    "        ## Resize the image to 1600x900    \n",
    "        coco_img = cv2.resize(coco_img, (WIDTH, HEIGHT), interpolation = cv2.INTER_LINEAR) \n",
    "        \n",
    "        ## Paste templates into the image\n",
    "        coco_img, errors, regions_list = pasteTemplateIntoCocoImage(coco_img, templates_list, templates_dict) \n",
    "        totalErrors += errors   #Add errors to total errors      \n",
    "        \n",
    "        if blurry:\n",
    "            coco_img = addBlur(coco_img) #Add blur to the image\n",
    "            \n",
    "        if SAVE:\n",
    "            ## Save the image to the disk\n",
    "            cv2.imwrite(f'./Img/ArtificialSamples/{name}.jpg', coco_img) \n",
    "            ## Get the size of the image\n",
    "            img_size = str(os.stat(f'./Img/ArtificialSamples/{name}.jpg').st_size) \n",
    "            if ANNOTATIONS:\n",
    "        \n",
    "                img_annotation = { \n",
    "                    name+'.jpg'+img_size: \n",
    "                    {\n",
    "                        \"filename\": name+'.jpg',\n",
    "                        \"size\": img_size,\n",
    "                        \"regions\": regions_list,\n",
    "                        \"file_attributes\": {}\n",
    "                    }\n",
    "                }\n",
    "\n",
    "                annot_obj.update(img_annotation) # Add image annotation to the object\n",
    "                    \n",
    "        img_list.append(coco_img)\n",
    "                \n",
    "    return annot_obj, totalErrors\n",
    "\n",
    "    # cv2.imshow('Img', img_list[1])\n",
    "    # cv2.waitKey(0)\n",
    "\n",
    "# Split the list into sublists of 3000 elements each, otherwise the program has chances to crash\n",
    "sublists = [coco_imgs_list[x:x+100] for x in range(0, len(coco_imgs_list), 100)] \n",
    "errors_counter = 0\n",
    "for lst in sublists:\n",
    "    new_annotations, errors = createSampleImages(templates_dict, lst, templates_list, blurry=True)\n",
    "    errors_counter += errors\n",
    "    # Save the annotations to the disk\n",
    "    if SAVE:\n",
    "        annotations.update(new_annotations)\n",
    "print(f'Total errors: {errors_counter/3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1bbf70f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./Img/annotations.json', 'r+') as jsonFile:\n",
    "#     _annotations = json.load(jsonFile)\n",
    "#     for image in _annotations.values():\n",
    "#         for region in image['regions']:\n",
    "#             classType = region[\"region_attributes\"][\"class\"]\n",
    "#             if classType == 'SAE':\n",
    "#                 region[\"region_attributes\"][\"class\"] = \"I-SA\"\n",
    "#             if classType == 'MP1' or classType == 'MP2' or classType == 'MP3':\n",
    "#                 region[\"region_attributes\"][\"class\"] = \"O-MP\"\n",
    "#             if classType == \"R-19-V\" or classType == \"R-19-H\":\n",
    "#                 region[\"region_attributes\"][\"class\"] = \"R-19\"\n",
    "#     jsonFile.seek(0)\n",
    "#     json.dump(_annotations, jsonFile)\n",
    "#     jsonFile.truncate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5fee70f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'R-19': 158,\n",
       " 'O-MP': 146,\n",
       " 'R-24a': 69,\n",
       " 'I-SA': 60,\n",
       " 'R-2': 43,\n",
       " 'R-6c': 20,\n",
       " 'R-15': 18,\n",
       " 'A-32b': 11,\n",
       " 'A-24': 10,\n",
       " 'A-32a': 4,\n",
       " 'R-5a': 4,\n",
       " 'R-3': 1,\n",
       " 'R-5b': 1}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_and_count_classes(annotation):\n",
    "    classes = {}\n",
    "\n",
    "    for image in annotation.values():\n",
    "        for region in image[\"regions\"]:\n",
    "            classType = region[\"region_attributes\"][\"class\"]\n",
    "            classes[classType] = classes.get(classType, 0) + 1\n",
    "\n",
    "    return classes\n",
    "\n",
    "def get_ordered_classes(ann_path):\n",
    "    if not os.path.exists(ann_path):\n",
    "        assert False, \"Invalid annotation path\"\n",
    "\n",
    "    with open(ann_path, \"r\") as f:\n",
    "        _annotations = json.load(f)\n",
    "        \n",
    "    class_hist = extract_and_count_classes(_annotations)\n",
    "\n",
    "    return dict(sorted(class_hist.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "get_ordered_classes('./Img/annotations.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9b60ebf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# \n",
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "with open('./Img/new_annotations.json', 'w') as f:\n",
    "    json.dump(annotations, f, cls=NpEncoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f65bf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b2ae59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c9eda5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tensorflow25')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e58c90c1a3b05fc421967660c466c67c2fd21820cf1f6ba41a9eb258f9783709"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
