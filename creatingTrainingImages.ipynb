{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "896ee4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fbfd59b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Variables\n",
    "WIDTH = 1600\n",
    "HEIGHT = 900\n",
    "ORANGE_BACKGROUND = [12, 255, 255]\n",
    "ROOT_DIR = os.path.abspath(\"./\")\n",
    "IMGS_DIR = os.path.join(ROOT_DIR, \"Img\")\n",
    "ANNOTATIONS_DIR = os.path.join(IMGS_DIR, \"annotations.json\")\n",
    "TEMPLATES_DIR = os.path.join(IMGS_DIR, \"RawOrangeSignImgs\")\n",
    "COCO_IMGS_DIR = os.path.join(ROOT_DIR, \"coco_dataset\", \"chosenImages\")\n",
    "f = open(ANNOTATIONS_DIR, 'r')\n",
    "annotations = json.load(f)\n",
    "orange_signs_list = os.listdir(TEMPLATES_DIR)\n",
    "coco_imgs_list = os.listdir(COCO_IMGS_DIR)\n",
    "templates_list = orange_signs_list\n",
    "\n",
    "#Reduce the quantity to test the program\n",
    "coco_imgs_list = coco_imgs_list[:5000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fadf6087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyErosion(mask):\n",
    "    '''\n",
    "    Apply Erosion to the mask.\n",
    "    -Erosion makes the mask smaller and removes noise.\n",
    "    :param mask: Mask to be eroded.\n",
    "    :return: Eroded mask.   \n",
    "    ''' \n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    mask = cv2.erode(mask, kernel, iterations=1)\n",
    "    return mask\n",
    "\n",
    "def getContours(mask):\n",
    "    '''\n",
    "    Uses OpenCV to find the contours of the mask.\n",
    "    To be a valid contour, it must have an area of at least 600pxÂ².\n",
    "    :param mask: Mask to be used to find contours.\n",
    "    :return: List of valid contours. \n",
    "    '''\n",
    "    valid_contours_list = []\n",
    "    contours, hierarchy = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for c in contours:\n",
    "        area = cv2.contourArea(c)\n",
    "        if area < 600:\n",
    "            continue\n",
    "        valid_contours_list.append(c)\n",
    "    return valid_contours_list\n",
    "\n",
    "def createMask(img):\n",
    "    '''\n",
    "    Creates a mask from the image.\n",
    "    In this project the image is a sign with a orange background.\n",
    "    :param img: Image to be used to create the mask.\n",
    "    :return: Mask created from the image.\n",
    "    '''\n",
    "    hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)  #Convert img from BGR to HSV\n",
    "    # print(\"HSV Img Shape: \", hsv_img.shape)\n",
    "\n",
    "    lower_limit = np.array(ORANGE_BACKGROUND) #Background HSV Color to create mask\n",
    "    upper_limit = np.array(ORANGE_BACKGROUND) #Background HSV Color to create mask\n",
    "\n",
    "    mask = cv2.inRange(hsv_img, lower_limit, upper_limit) #Select Orange area\n",
    "    mask_inv = cv2.bitwise_not(mask)   #Invert mask (deselect orang area) and select sign area       \n",
    "    mask_inv = applyErosion(mask_inv)       #Erode the mask to remove noise\n",
    "    #print(\"Mask-Inv Shape:\" + mask_inv.shape)  #should be (h, w, 3)\n",
    "    \n",
    "    return mask_inv\n",
    "\n",
    "def randomResize(img):\n",
    "    '''\n",
    "    Resizes the image to a random size.\n",
    "    :param img: Image to be resized.\n",
    "    :return: Resized image.\n",
    "    '''\n",
    "    random_scale = random.uniform(0.4, 1.1)\n",
    "    width, height = int(img.shape[1] * random_scale), int(img.shape[0] * random_scale)\n",
    "    img = cv2.resize(img, (width, height), interpolation=cv2.INTER_AREA)\n",
    "    return img\n",
    "\n",
    "\n",
    "def createTemplate(orange_signs_list):\n",
    "    '''\n",
    "    Creates a template for every orange sign from input list. \n",
    "    And saves it in a dictionary.\n",
    "    :param orange_signs_list: List of orange signs loaded from ./Img/RawOriginSign.\n",
    "    :return template_dict: Dictionary with the templates for each orange sign.\n",
    "    \n",
    "    template_dict = { sign_type1: [(sing_number, sign_rgba, contours_list)]\n",
    "                      sign_type2: [(sing_number, sign_rgba, contours_list), \n",
    "                                   (sing_number, sign_rgba, contours_list)]\n",
    "                      ...}),\n",
    "    '''\n",
    "    templates_dict = {}\n",
    "    for name in orange_signs_list:\n",
    "        name = name[:-4:]               # remove .jpg\n",
    "        sign_type = name[:-4:]          # select the sign type\n",
    "        sign_number = name[-4::]        # select the number of this sign type\n",
    "        img = cv2.imread(f'./Img/RawOrangeSignImgs/{sign_type + sign_number}.jpg')\n",
    "        img = randomResize(img)\n",
    "        # cv2.imshow(\"Img\", img)\n",
    "        # print('Img Shape:', img.shape)     \n",
    "\n",
    "        mask = createMask(img)\n",
    "        contours_list = getContours(mask) #Needed to the annotations\n",
    "\n",
    "        ## Using mask to select orange area and cut it from img, creating a transparent sign template\n",
    "        sign = cv2.bitwise_and(img, img, mask= mask)\n",
    "        ## Convert to RGBA (RGB with Alpha Channel)\n",
    "        sign_rgba = cv2.cvtColor(sign, cv2.COLOR_BGR2BGRA)\n",
    "        sign_rgba[:,:,3] = mask     #Add mask to alpha channel\n",
    "\n",
    "        ## Add new tuple to dictionary if it doesn't exist\n",
    "        if not templates_dict.get(sign_type):  \n",
    "            templates_dict[sign_type] = [(sign_number, sign_rgba, contours_list)]\n",
    "        ## The tuples contains the sign number (_XXX), sign image -> RGBA: (XXX, XXX, 4)) \n",
    "        # and contours list [shape: (n, 1, 2)]]                                 \n",
    "        else: \n",
    "            templates_dict[sign_type].append((sign_number, sign_rgba, contours_list))\n",
    "    \n",
    "    return templates_dict\n",
    "        \n",
    "templates_dict = createTemplate(orange_signs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e9ebc380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total errors: 30.0\n"
     ]
    }
   ],
   "source": [
    "SAVE = True\n",
    "ANNOTATIONS = True\n",
    "DRAW_CONTOURS = False\n",
    "avaiable_types = list(templates_dict.keys())\n",
    "avaiable_templates = set(orange_signs_list)\n",
    "\n",
    "def addBlur(img):\n",
    "    '''\n",
    "    Adds a blur to the image.\n",
    "    :param img: Image to be blurred.\n",
    "    :return: Blurred image.\n",
    "    '''\n",
    "    kernel = np.ones((5,5), np.float32)/25  #Blur kernel with a size of 5x5 and a factor of 1/25 (default)\n",
    "    img = cv2.filter2D(img, -1, kernel)     #Blur image using kernel\n",
    "    return img\n",
    "\n",
    "def checkIntervals(a, b, c, d):\n",
    "    '''\n",
    "    Checks if a < b and c < d.\n",
    "    :param a: First interval start.\n",
    "    :param b: First interval end.\n",
    "    :param c: Second interval start.\n",
    "    :param d: Second interval end.\n",
    "    :return: True if b-a and d-c are greater than 0, False otherwise.\n",
    "    '''\n",
    "    if a < b and c < d:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def chooseOffset(i, temp_w, temp_h):\n",
    "    '''\n",
    "    Depending on the quadrant we are drawing the template, we choose a different random offset.\n",
    "    :param i: Quadrant we are drawing the template.\n",
    "    :param temp_w: Template width.\n",
    "    :param temp_h: Template height.\n",
    "    :return: Random offset for the specific quadrant.\n",
    "    '''\n",
    "    if i == 0:\n",
    "        valid_intervals = checkIntervals(temp_w, WIDTH/2-temp_w, temp_h, HEIGHT/2-temp_h)\n",
    "        # Change these to change the position of first sign\n",
    "        if valid_intervals:\n",
    "            x_offset, y_offset= np.random.randint(temp_w, WIDTH/2-temp_w), np.random.randint(temp_h, HEIGHT/2-temp_h)     \n",
    "        else:\n",
    "            x_offset, y_offset= np.random.randint(5, temp_w), np.random.randint(5, temp_h)     \n",
    "    elif i == 1:\n",
    "        valid_intervals = checkIntervals(WIDTH/2+temp_w, WIDTH - temp_w, temp_h, HEIGHT/2-temp_h)\n",
    "        # Change these to change the position of second sign\n",
    "        if valid_intervals:\n",
    "            x_offset, y_offset= np.random.randint(WIDTH/2 + temp_w, WIDTH - temp_w), np.random.randint(temp_h, HEIGHT/2-temp_h)     \n",
    "        else:\n",
    "            x_offset, y_offset= np.random.randint(WIDTH/2, WIDTH/2 + temp_w), np.random.randint(10, temp_h)     \n",
    "    elif i == 2:\n",
    "        valid_intervals = checkIntervals(temp_w, WIDTH/2 - temp_w, HEIGHT/2+temp_h, HEIGHT - temp_h)\n",
    "        # Change these to change the position of third sign\n",
    "        if valid_intervals:\n",
    "            x_offset, y_offset= np.random.randint(temp_w, WIDTH/2 - temp_w), np.random.randint(HEIGHT/2 + temp_h, HEIGHT - temp_h)\n",
    "        else:\n",
    "            x_offset, y_offset= np.random.randint(10, temp_w), np.random.randint(HEIGHT/2 + 10, HEIGHT/2 + temp_h)\n",
    "    else:\n",
    "        valid_intervals = checkIntervals(WIDTH/2+temp_w, WIDTH - temp_w, HEIGHT/2+temp_h, HEIGHT - temp_h)\n",
    "        # Change these to change the position of fourth sign\n",
    "        if valid_intervals:\n",
    "            x_offset, y_offset= np.random.randint(WIDTH/2+temp_w, WIDTH - temp_h), np.random.randint(HEIGHT/2+temp_h, HEIGHT-temp_h)     \n",
    "        else:\n",
    "            x_offset, y_offset= np.random.randint(WIDTH/2+10, WIDTH/2 + temp_w), np.random.randint(HEIGHT/2+10, HEIGHT/2 + temp_h)\n",
    "\n",
    "    return x_offset, y_offset\n",
    "\n",
    "\n",
    "def addOffsetToContour(x_offset, y_offset, contours): \n",
    "    '''\n",
    "    Add offset to contours according to the position that we paste the sign template.\n",
    "    :param x_offset: X offset.\n",
    "    :param y_offset: Y offset.\n",
    "    :param contours: Contours to be offset.\n",
    "    :return: Offsetted contours.\n",
    "    '''\n",
    "    for contour in contours:\n",
    "        new_contour = contour + (x_offset, y_offset)\n",
    "    return new_contour\n",
    "\n",
    "\n",
    "def createPointsFromContours(contours):\n",
    "    '''\n",
    "    Create list of points_x and points_y from contours, to be used for create JSON object for annotations.\n",
    "    :param contours: Contours that gonna be used to extract values for points_x and points_y.\n",
    "    :return: Two lists: points_x, points_y\n",
    "    '''\n",
    "    points_x = []\n",
    "    points_y = []\n",
    "    for contour in contours:\n",
    "        for point in contour:\n",
    "            points_x.append(point[0])\n",
    "            points_y.append(point[1])\n",
    "    assert len(points_x) == len(points_y), \"Error: points_x and points_y have different length\"    \n",
    "    return points_x, points_y\n",
    "\n",
    "def selectTemplates(numberOfSigns):\n",
    "    '''\n",
    "    Selects the templates that are going to be used in the image.\n",
    "    Trying to create a constant distribution of type of signs.\n",
    "    :param numberOfSigns: Number of signs that are going to be used in the image.   \n",
    "    '''\n",
    "    global avaiable_templates, avaiable_types\n",
    "    chosen_list = []\n",
    "\n",
    "    while numberOfSigns > 0:\n",
    "        if len(avaiable_types) == 0:\n",
    "            avaiable_types = list(templates_dict.keys())\n",
    "        chosen_type = random.choice(avaiable_types) # Choose a random type of sign\n",
    "        avaiable_types.remove(chosen_type)          # Remove the chosen type from the list\n",
    "        # Get the list of templates of the chosen type\n",
    "        chosen_ones = [_ for _ in avaiable_templates if chosen_type+'_' in _]\n",
    "        #print(chosen_ones)\n",
    "        # Choose a random template from the chosen type\n",
    "        chosen = random.choice(chosen_ones) \n",
    "        chosen = chosen[:-4:]\n",
    "        # Add the chosen template to the list of chosen templates\n",
    "        chosen_list.append(chosen)\n",
    "        numberOfSigns -= 1\n",
    "\n",
    "        \n",
    "    return chosen_list\n",
    "\n",
    "\n",
    "\n",
    "def pasteTemplateIntoCocoImage(coco_img, templates_list, templates_dict):\n",
    "    '''\n",
    "    Uses arbitrary image `coco_img` and pastes beteen 1 and 4 templates of random signs into it.\n",
    "    :param coco_img: Image to be used to paste templates.\n",
    "    :param templates_list: List of templates with 3 sublists, each of then containnig signs of one these categories:\n",
    "        Daily: Signs that are the most for the day user.\n",
    "        Frequent: Signs that everybody have seen at least once.\n",
    "        Uncommom: Signs that probably aren't used often and fewer people know about them.\n",
    "    :param templates_dict: Dictionary with the templates and contours for each sign.\n",
    "    :return coco_img, countErrors, regions: Image with templates pasted, number of errors when pasting and regions to be used for annotations.\n",
    "    '''\n",
    "    countErrors = 0\n",
    "    numberOfSigns = np.random.randint(1, 5) # Random number of signs to be placed in the image [1, 4]\n",
    "    \n",
    "    ## Unpack templates_list\n",
    "    #daily_templates_list, frequent_templates_list, uncommom_templates_list = templates_list[0] \n",
    "    \n",
    "    chosen_list = [] # List to save 1 to 4 signs templates to paste in the image\n",
    "    regions = [] # List to save object of regions to be used for annotations\n",
    "\n",
    "    chosen_list = selectTemplates(numberOfSigns)\n",
    "      \n",
    "    \n",
    "    for i, sign in enumerate(chosen_list):\n",
    "        sign_number = int(sign[-3::]) # select the number of this sign type\n",
    "        sign_type = sign[:-4:] # select the sign type\n",
    "\n",
    "        template_tuple = templates_dict[sign_type][sign_number] # get the template tuple for this sign\n",
    "        template = template_tuple[1] # get the template image\n",
    "        temp_h, temp_w, _ = template.shape # template height and width\n",
    "        # print(template.shape)\n",
    "        \n",
    "        ## Choose offset for the chosen sign template\n",
    "        x_offset, y_offset = chooseOffset(i, temp_w, temp_h) \n",
    "        \n",
    "        ## Using the offset to drag the image down and to the right    \n",
    "        y1, y2 = y_offset, y_offset + template.shape[0]\n",
    "        x1, x2 = x_offset, x_offset + template.shape[1]\n",
    "\n",
    "        alpha_s = template[:, :, 3] / 255.0 # get the alpha channel of the template\n",
    "        alpha_l = 1.0 - alpha_s  # alpha_l is the alpha of the background of the template\n",
    "        \n",
    "        for c in range(0, 3):\n",
    "            try:\n",
    "                ## paste the template on the image\n",
    "                coco_img[y1:y2, x1:x2, c] = (alpha_s * template[:, :, c] +\n",
    "                                    alpha_l * coco_img[y1:y2, x1:x2, c])   \n",
    "                ## Add offset to contours\n",
    "                template_countour = addOffsetToContour(x_offset, y_offset, template_tuple[2])  \n",
    "\n",
    "                if DRAW_CONTOURS:\n",
    "                    ## Draw contours on the images to check if positions are correct\n",
    "                    cv2.drawContours(coco_img, [template_countour], -1, (0, 255, 0), 3) \n",
    "                \n",
    "                ## Create points_x and points_y from contours for annotations    \n",
    "                points_x, points_y = createPointsFromContours(template_countour)    \n",
    "\n",
    "                annot_obj = {           # Create object to convert for JSON annotations\n",
    "                    \"shape_attributes\": {\n",
    "                        \"name\": \"polygon\",\n",
    "                        \"all_points_x\": points_x,\n",
    "                        \"all_points_y\": points_y\n",
    "                    },\n",
    "                    \"region_attributes\": \n",
    "                        {\n",
    "                            \"class\": sign_type\n",
    "                        }\n",
    "                }\n",
    "                regions.append(annot_obj) # Add JSON object to regions list\n",
    "            except:\n",
    "                countErrors+= 1 # if the template is bigger than the image, the program will crash\n",
    "                #print(f\"Error pasting template {sign_type}_{sign_number} into image\")\n",
    "                continue  \n",
    "        \n",
    "    return coco_img, countErrors, regions\n",
    "\n",
    "def createSampleImages(templates_dict, coco_imgs_list, templates_list, blurry):\n",
    "    '''\n",
    "    Creates artificial images with templates of signs pasted in them.\n",
    "    :param templates_dict: Dictionary with the templates and contours for each sign.\n",
    "    :param coco_imgs_list: List of images to be used to paste templates.\n",
    "    :param templates_list: List of templates with 3 sublists, each of then containnig signs of one these categories:\n",
    "        Daily: Signs that are the most for the day user.\n",
    "        Frequent: Signs that everybody have seen at least once.\n",
    "        Uncommom: Signs that probably aren't used often and fewer people know about them.\n",
    "    :param blurry: Boolean variable to determine if the images will be blurred or not.\n",
    "    :return: Object with annotations for all images generated.\n",
    "    '''\n",
    "    img_list = []\n",
    "    annot_obj = {}     # Create empty object to save annotations\n",
    "    totalErrors = 0    # Count Errors when trying to paste the template into the image\n",
    "\n",
    "\n",
    "    \n",
    "    for name in coco_imgs_list:\n",
    "        name = name[:-4:]       # remove .jpg\n",
    "        coco_img = cv2.imread(f'./coco_dataset/chosenImages/{name}.jpg')\n",
    "        ## Eliminate images with height greater than width (portraits)   \n",
    "        if(coco_img.shape[0] > coco_img.shape[1]):    \n",
    "            continue\n",
    "\n",
    "        ## Resize the image to 1600x900    \n",
    "        coco_img = cv2.resize(coco_img, (WIDTH, HEIGHT), interpolation = cv2.INTER_LINEAR) \n",
    "        \n",
    "        ## Paste templates into the image\n",
    "        coco_img, errors, regions_list = pasteTemplateIntoCocoImage(coco_img, templates_list, templates_dict) \n",
    "        totalErrors += errors   #Add errors to total errors      \n",
    "        \n",
    "        if blurry:\n",
    "            coco_img = addBlur(coco_img) #Add blur to the image\n",
    "            \n",
    "        if SAVE:\n",
    "            ## Save the image to the disk\n",
    "            cv2.imwrite(f'./Img/ArtificialSamples/{name}.jpg', coco_img) \n",
    "            ## Get the size of the image\n",
    "            img_size = str(os.stat(f'./Img/ArtificialSamples/{name}.jpg').st_size) \n",
    "            if ANNOTATIONS:\n",
    "        \n",
    "                img_annotation = { \n",
    "                    name+'.jpg'+img_size: \n",
    "                    {\n",
    "                        \"filename\": name+'.jpg',\n",
    "                        \"size\": img_size,\n",
    "                        \"regions\": regions_list,\n",
    "                        \"file_attributes\": {}\n",
    "                    }\n",
    "                }\n",
    "\n",
    "                annot_obj.update(img_annotation) # Add image annotation to the object\n",
    "                    \n",
    "        img_list.append(coco_img)\n",
    "                \n",
    "    return annot_obj, totalErrors\n",
    "\n",
    "    # cv2.imshow('Img', img_list[1])\n",
    "    # cv2.waitKey(0)\n",
    "\n",
    "# Split the list into sublists of 3000 elements each, otherwise the program has chances to crash\n",
    "sublists = [coco_imgs_list[x:x+100] for x in range(0, len(coco_imgs_list), 100)] \n",
    "errors_counter = 0\n",
    "for lst in sublists:\n",
    "    new_annotations, errors = createSampleImages(templates_dict, lst, templates_list, blurry=True)\n",
    "    errors_counter += errors\n",
    "    # Save the annotations to the disk\n",
    "    if SAVE:\n",
    "        annotations.update(new_annotations)\n",
    "print(f'Total errors: {errors_counter/3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbf70f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./Img/annotations.json', 'r+') as jsonFile:\n",
    "#     _annotations = json.load(jsonFile)\n",
    "#     for image in _annotations.values():\n",
    "#         for region in image['regions']:\n",
    "#             classType = region[\"region_attributes\"][\"class\"]\n",
    "#             if classType == 'SAE':\n",
    "#                 region[\"region_attributes\"][\"class\"] = \"I-SA\"\n",
    "#             if classType == 'MP1' or classType == 'MP2' or classType == 'MP3':\n",
    "#                 region[\"region_attributes\"][\"class\"] = \"O-MP\"\n",
    "#             if classType == \"R-19-V\" or classType == \"R-19-H\":\n",
    "#                 region[\"region_attributes\"][\"class\"] = \"R-19\"\n",
    "#     jsonFile.seek(0)\n",
    "#     json.dump(_annotations, jsonFile)\n",
    "#     jsonFile.truncate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9b60ebf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# \n",
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "with open('./Img/new_annotations.json', 'w') as f:\n",
    "    json.dump(annotations, f, cls=NpEncoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fee70f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'R-19': 158,\n",
       " 'O-MP': 146,\n",
       " 'R-24a': 69,\n",
       " 'I-SA': 60,\n",
       " 'R-2': 43,\n",
       " 'R-6c': 20,\n",
       " 'R-15': 18,\n",
       " 'A-32b': 11,\n",
       " 'A-24': 10,\n",
       " 'A-32a': 4,\n",
       " 'R-5a': 4,\n",
       " 'R-3': 1,\n",
       " 'R-5b': 1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_and_count_classes(annotation):\n",
    "    classes = {}\n",
    "\n",
    "    for image in annotation.values():\n",
    "        for region in image[\"regions\"]:\n",
    "            classType = region[\"region_attributes\"][\"class\"]\n",
    "            classes[classType] = classes.get(classType, 0) + 1\n",
    "\n",
    "    return classes\n",
    "\n",
    "def get_ordered_classes(ann_path):\n",
    "    if not os.path.exists(ann_path):\n",
    "        assert False, \"Invalid annotation path\"\n",
    "\n",
    "    with open(ann_path, \"r\") as f:\n",
    "        _annotations = json.load(f)\n",
    "        \n",
    "    class_hist = extract_and_count_classes(_annotations)\n",
    "\n",
    "    return dict(sorted(class_hist.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "get_ordered_classes('./Img/annotations.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b3c901e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'R-19': 275,\n",
       " 'O-MP': 257,\n",
       " 'R-24a': 186,\n",
       " 'I-SA': 174,\n",
       " 'R-2': 160,\n",
       " 'R-6c': 137,\n",
       " 'R-15': 132,\n",
       " 'A-24': 127,\n",
       " 'A-32b': 125,\n",
       " 'A-32a': 121,\n",
       " 'R-5a': 121,\n",
       " 'R-3': 118,\n",
       " 'R-5b': 118,\n",
       " 'T-TAR01': 117,\n",
       " 'A-48': 117,\n",
       " 'A-37': 117,\n",
       " 'T-THC05': 117,\n",
       " 'T-SAU08': 117,\n",
       " 'T-TAD11': 117,\n",
       " 'T-TIT08': 117,\n",
       " 'O-OA42a': 117,\n",
       " 'A-33a': 117,\n",
       " 'A-30b': 117,\n",
       " 'I-SA18': 117,\n",
       " 'A-10b': 117,\n",
       " 'O-OA38': 117,\n",
       " 'O-OA18': 117,\n",
       " 'A-47': 117,\n",
       " 'A-34': 117,\n",
       " 'R-6a': 117,\n",
       " 'T-SAU13': 117,\n",
       " 'O-OA19': 117,\n",
       " 'T-THC04': 117,\n",
       " 'R-40': 117,\n",
       " 'T-TAR02': 117,\n",
       " 'T-TAD06': 117,\n",
       " 'A-11a': 117,\n",
       " 'T-TAR06': 117,\n",
       " 'I-SA12': 117,\n",
       " 'R-30': 117,\n",
       " 'R-32': 117,\n",
       " 'R-16': 117,\n",
       " 'I-SA20': 117,\n",
       " 'A-22': 117,\n",
       " 'A-31': 117,\n",
       " 'T-SAU07': 117,\n",
       " 'A-29': 117,\n",
       " 'R-17': 117,\n",
       " 'A-38': 117,\n",
       " 'O-OA21b': 117,\n",
       " 'T-TAD15': 117,\n",
       " 'T-I': 117,\n",
       " 'T-SAU20': 117,\n",
       " 'R-39': 117,\n",
       " 'T-TAR05': 117,\n",
       " 'A-13a': 117,\n",
       " 'I-SA02': 117,\n",
       " 'R-33': 117,\n",
       " 'R-25a': 117,\n",
       " 'I-SA24': 117,\n",
       " 'R-8b': 117,\n",
       " 'A-25': 117,\n",
       " 'A-16': 117,\n",
       " 'T-TIT09': 117,\n",
       " 'T-TNA03': 117,\n",
       " 'T-TAD04': 117,\n",
       " 'O-OA28': 117,\n",
       " 'R-1': 117,\n",
       " 'A-14': 117,\n",
       " 'A-8': 117,\n",
       " 'T-TIT07': 117,\n",
       " 'R-26': 117,\n",
       " 'R-36b': 117,\n",
       " 'T-THC07': 117,\n",
       " 'T-THC09': 117,\n",
       " 'T-SAU01': 117,\n",
       " 'T-SAU25': 117,\n",
       " 'A-42a': 117,\n",
       " 'A-7a': 117,\n",
       " 'R-37': 117,\n",
       " 'A-46': 117,\n",
       " 'T-THC10': 117,\n",
       " 'R-10': 117,\n",
       " 'R-13': 117,\n",
       " 'T-SAU11': 117,\n",
       " 'T-TIT01': 117,\n",
       " 'A-28': 117,\n",
       " 'A-19': 117,\n",
       " 'R-14': 117,\n",
       " 'R-36a': 117,\n",
       " 'T-SAU12': 117,\n",
       " 'T-TIT05': 117,\n",
       " 'A-21c': 117,\n",
       " 'O-OA24': 117,\n",
       " 'I-SA07': 117,\n",
       " 'T-TNA02': 117,\n",
       " 'R-4b': 117,\n",
       " 'O-OA29': 117,\n",
       " 'I-IK': 117,\n",
       " 'A-6': 117,\n",
       " 'I-SA01': 117,\n",
       " 'O-OA17': 117,\n",
       " 'T-TAR04': 117,\n",
       " 'A-23': 117,\n",
       " 'T-SAU04': 117,\n",
       " 'R-24b': 117,\n",
       " 'R-20': 117,\n",
       " 'A-30a': 117,\n",
       " 'A-4a': 117,\n",
       " 'T-SAU24': 117,\n",
       " 'T-THC01': 117,\n",
       " 'T-TAD05': 117,\n",
       " 'T-TNA01': 117,\n",
       " 'R-25b': 117,\n",
       " 'T-SAU06': 117,\n",
       " 'T-THC11': 117,\n",
       " 'O-OA15': 117,\n",
       " 'A-10a': 117,\n",
       " 'I-SA11': 117,\n",
       " 'T-SAU19': 117,\n",
       " 'T-TNA05': 117,\n",
       " 'T-SAU22': 117,\n",
       " 'R-11': 117,\n",
       " 'T-TIT03': 117,\n",
       " 'A-2a': 117,\n",
       " 'I-SA14': 117,\n",
       " 'T-TAD14': 117,\n",
       " 'A-20b': 117,\n",
       " 'T-TIT10': 117,\n",
       " 'A-36': 117,\n",
       " 'A-18': 117,\n",
       " 'T-SAU09': 117,\n",
       " 'I-SA08': 117,\n",
       " 'T-SAU10': 117,\n",
       " 'T-TNA08': 117,\n",
       " 'T-TAR03': 117,\n",
       " 'O-OA27': 117,\n",
       " 'A-15': 117,\n",
       " 'R-21': 117,\n",
       " 'A-11b': 117,\n",
       " 'T-TIT02': 117,\n",
       " 'A-9': 117,\n",
       " 'T-TNA07': 117,\n",
       " 'T-TAD08': 117,\n",
       " 'I-SA26': 117,\n",
       " 'A-IC': 117,\n",
       " 'I-SA06': 117,\n",
       " 'T-TAD12': 117,\n",
       " 'A-20a': 117,\n",
       " 'R-8a': 117,\n",
       " 'A-1a': 117,\n",
       " 'A-44': 117,\n",
       " 'T-TNA04': 117,\n",
       " 'A-21e': 117,\n",
       " 'I-SA10': 117,\n",
       " 'A-45': 117,\n",
       " 'T-SAU03': 117,\n",
       " 'A-17': 117,\n",
       " 'T-TNA06': 117,\n",
       " 'O-MA': 117,\n",
       " 'R-38': 117,\n",
       " 'T-TIT06': 117,\n",
       " 'A-21d': 117,\n",
       " 'T-THC08': 117,\n",
       " 'A-21a': 117,\n",
       " 'A-42c': 117,\n",
       " 'T-SAU02': 117,\n",
       " 'T-TAD02': 117,\n",
       " 'T-TIT04': 117,\n",
       " 'A-1b': 117,\n",
       " 'A-27': 117,\n",
       " 'T-TAD07': 117,\n",
       " 'O-SC': 117,\n",
       " 'R-9': 117,\n",
       " 'T-TAR07': 117,\n",
       " 'T-SAU14': 117,\n",
       " 'T-TAD16': 117,\n",
       " 'R-23': 117,\n",
       " 'R-18': 117,\n",
       " 'A-3b': 117,\n",
       " 'T-TAD10': 117,\n",
       " 'I-SA21': 117,\n",
       " 'R-29': 117,\n",
       " 'A-33b': 117,\n",
       " 'T-SAU23': 117,\n",
       " 'T-TAD01': 117,\n",
       " 'R-4a': 117,\n",
       " 'R-IC': 117,\n",
       " 'R-22': 117,\n",
       " 'T-TAD03': 117,\n",
       " 'I-SA13': 117,\n",
       " 'A-3a': 117,\n",
       " 'A-7b': 117,\n",
       " 'R-27': 117,\n",
       " 'A-43': 114,\n",
       " 'A-13b': 114,\n",
       " 'O-OA37': 114,\n",
       " 'R-7': 114,\n",
       " 'O-FE': 114,\n",
       " 'T-TAD13': 114,\n",
       " 'T-SAU15': 114,\n",
       " 'A-4b': 114,\n",
       " 'I-O': 114,\n",
       " 'A-35': 114,\n",
       " 'A-SEA': 114,\n",
       " 'T-TAD09': 114,\n",
       " 'A-42b': 114,\n",
       " 'R-12': 114,\n",
       " 'T-SAU21': 114,\n",
       " 'A-26b': 114,\n",
       " 'O-O': 114,\n",
       " 'A-21b': 114,\n",
       " 'I-SA09': 114,\n",
       " 'R-35b': 114,\n",
       " 'A-26a': 114,\n",
       " 'R-25d': 114,\n",
       " 'A-41': 114,\n",
       " 'A-12': 114,\n",
       " 'T-SAU05': 114,\n",
       " 'R-28': 114,\n",
       " 'T-SAU26': 114,\n",
       " 'A-40': 114,\n",
       " 'T-TNA09': 114,\n",
       " 'R-35a': 114,\n",
       " 'T-THC02': 114,\n",
       " 'T-THC03': 114,\n",
       " 'A-5a': 114,\n",
       " 'I-I': 114,\n",
       " 'O-OA21a': 114,\n",
       " 'R-34': 114,\n",
       " 'T-THC06': 114,\n",
       " 'R-25c': 111,\n",
       " 'O-OA25': 111,\n",
       " 'I-SA19': 111,\n",
       " 'A-30c': 111,\n",
       " 'R-31': 111,\n",
       " 'I-E': 111,\n",
       " 'A-5b': 111,\n",
       " 'A-2b': 111,\n",
       " 'R-6b': 111,\n",
       " 'A-39': 108,\n",
       " 'O-OA21c': 108}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ordered_classes('./Img/new_annotations.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tensorflow25')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e58c90c1a3b05fc421967660c466c67c2fd21820cf1f6ba41a9eb258f9783709"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
