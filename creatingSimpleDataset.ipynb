{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "896ee4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbfd59b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Variables\n",
    "WIDTH = 1600\n",
    "HEIGHT = 900\n",
    "ORANGE_BACKGROUND = [12, 255, 255]\n",
    "ROOT_DIR = os.path.abspath(\"./\")\n",
    "IMGS_DIR = os.path.join(ROOT_DIR, \"simple_dataset\")\n",
    "f = open('./simple_dataset/annotations.json', 'r')\n",
    "annotations = json.load(f)\n",
    "orange_signs_list = os.listdir('./simple_dataset/RawOrangeSignImgs/')\n",
    "coco_imgs_list = os.listdir('./coco_dataset/chosenImages')\n",
    "# daily_templates_list = os.listdir('./simple_dataset/Templates/Daily')\n",
    "# frequent_templates_list = os.listdir('./simple_dataset/Templates/Frequent')\n",
    "# uncommom_templates_list = os.listdir('./simple_dataset/Templates/Uncommon') \n",
    "# templates_list = [(daily_templates_list, frequent_templates_list, \n",
    "#                    uncommom_templates_list)]\n",
    "templates_list = orange_signs_list\n",
    "\n",
    "#Reduce the quantity to test the program\n",
    "coco_imgs_list = coco_imgs_list[:500]\n",
    "\n",
    "# Total number of orange templates of signs\n",
    "orange_sings_list_length = len(orange_signs_list)  \n",
    "# Total number of templates of signs after categorized by frequency: Daily, Frequent, Uncommon\n",
    "#dfu_total_length = len(daily_templates_list) + len(frequent_templates_list) + len(uncommom_templates_list)\n",
    "# The length must be equal, and ideally all names that are present in the orange signs list must be present in one of the three categories of templates\n",
    "#assert orange_sings_list_length == dfu_total_length "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39e7a007",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./simple_dataset/annotations.json', 'r+') as jsonFile:\n",
    "    _annotations = json.load(jsonFile)\n",
    "    for image in _annotations.values():\n",
    "        for region in image['regions']:\n",
    "            classType = region[\"region_attributes\"][\"class\"]\n",
    "            if classType == 'SAE':\n",
    "                region[\"region_attributes\"][\"class\"] = \"I-SA\"\n",
    "            if classType == 'MP1' or classType == 'MP2' or classType == 'MP3':\n",
    "                region[\"region_attributes\"][\"class\"] = \"O-MP\"\n",
    "            if classType == \"R-19-V\" or classType == \"R-19-H\":\n",
    "                region[\"region_attributes\"][\"class\"] = \"R-19\"\n",
    "    jsonFile.seek(0)\n",
    "    json.dump(_annotations, jsonFile)\n",
    "    jsonFile.truncate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fadf6087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyErosion(mask):\n",
    "    '''\n",
    "    Apply Erosion to the mask.\n",
    "    -Erosion makes the mask smaller and removes noise.\n",
    "    :param mask: Mask to be eroded.\n",
    "    :return: Eroded mask.   \n",
    "    ''' \n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    mask = cv2.erode(mask, kernel, iterations=1)\n",
    "    return mask\n",
    "\n",
    "def getContours(mask):\n",
    "    '''\n",
    "    Uses OpenCV to find the contours of the mask.\n",
    "    To be a valid contour, it must have an area of at least 600pxÂ².\n",
    "    :param mask: Mask to be used to find contours.\n",
    "    :return: List of valid contours. \n",
    "    '''\n",
    "    valid_contours_list = []\n",
    "    contours, hierarchy = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for c in contours:\n",
    "        area = cv2.contourArea(c)\n",
    "        if area < 600:\n",
    "            continue\n",
    "        valid_contours_list.append(c)\n",
    "    return valid_contours_list\n",
    "\n",
    "def createMask(img):\n",
    "    '''\n",
    "    Creates a mask from the image.\n",
    "    In this project the image is a sign with a orange background.\n",
    "    :param img: Image to be used to create the mask.\n",
    "    :return: Mask created from the image.\n",
    "    '''\n",
    "    hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)  #Convert img from BGR to HSV\n",
    "    # print(\"HSV Img Shape: \", hsv_img.shape)\n",
    "\n",
    "    lower_limit = np.array(ORANGE_BACKGROUND) #Background HSV Color to create mask\n",
    "    upper_limit = np.array(ORANGE_BACKGROUND) #Background HSV Color to create mask\n",
    "\n",
    "    mask = cv2.inRange(hsv_img, lower_limit, upper_limit) #Select Orange area\n",
    "    mask_inv = cv2.bitwise_not(mask)   #Invert mask (deselect orang area) and select sign area       \n",
    "    mask_inv = applyErosion(mask_inv)       #Erode the mask to remove noise\n",
    "    #print(\"Mask-Inv Shape:\" + mask_inv.shape)  #should be (h, w, 3)\n",
    "    \n",
    "    return mask_inv\n",
    "\n",
    "def randomResize(img):\n",
    "    '''\n",
    "    Resizes the image to a random size.\n",
    "    :param img: Image to be resized.\n",
    "    :return: Resized image.\n",
    "    '''\n",
    "    random_scale = random.uniform(0.4, 1.1)\n",
    "    width, height = int(img.shape[1] * random_scale), int(img.shape[0] * random_scale)\n",
    "    img = cv2.resize(img, (width, height), interpolation=cv2.INTER_AREA)\n",
    "    return img\n",
    "\n",
    "\n",
    "def createTemplate(orange_signs_list):\n",
    "    '''\n",
    "    Creates a template for every orange sign from input list. \n",
    "    And saves it in a dictionary.\n",
    "    :param orange_signs_list: List of orange signs loaded from ./Img/RawOriginSign.\n",
    "    :return template_dict: Dictionary with the templates for each orange sign.\n",
    "    \n",
    "    template_dict = { sign_type1: [(sing_number, sign_rgba, contours_list)]\n",
    "                      sign_type2: [(sing_number, sign_rgba, contours_list), \n",
    "                                   (sing_number, sign_rgba, contours_list)]\n",
    "                      ...}),\n",
    "    '''\n",
    "    templates_dict = {}\n",
    "    for name in orange_signs_list:\n",
    "        name = name[:-4:]               # remove .jpg\n",
    "        sign_type = name[:-4:]          # select the sign type\n",
    "        sign_number = name[-4::]        # select the number of this sign type\n",
    "        img = cv2.imread(f'./simple_dataset/RawOrangeSignImgs/{sign_type + sign_number}.jpg')\n",
    "        img = randomResize(img)\n",
    "        # cv2.imshow(\"Img\", img)\n",
    "        # print('Img Shape:', img.shape)     \n",
    "\n",
    "        mask = createMask(img)\n",
    "        contours_list = getContours(mask) #Needed to the annotations\n",
    "\n",
    "        ## Using mask to select orange area and cut it from img, creating a transparent sign template\n",
    "        sign = cv2.bitwise_and(img, img, mask= mask)\n",
    "        ## Convert to RGBA (RGB with Alpha Channel)\n",
    "        sign_rgba = cv2.cvtColor(sign, cv2.COLOR_BGR2BGRA)\n",
    "        sign_rgba[:,:,3] = mask     #Add mask to alpha channel\n",
    "\n",
    "        ## Add new tuple to dictionary if it doesn't exist\n",
    "        if not templates_dict.get(sign_type):  \n",
    "            templates_dict[sign_type] = [(sign_number, sign_rgba, contours_list)]\n",
    "        ## The tuples contains the sign number (_XXX), sign image -> RGBA: (XXX, XXX, 4)) \n",
    "        # and contours list [shape: (n, 1, 2)]]                                 \n",
    "        else: \n",
    "            templates_dict[sign_type].append((sign_number, sign_rgba, contours_list))\n",
    "    \n",
    "    return templates_dict\n",
    "        \n",
    "templates_dict = createTemplate(orange_signs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9ebc380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total errors: 5.0\n"
     ]
    }
   ],
   "source": [
    "SAVE = True\n",
    "ANNOTATIONS = True\n",
    "DRAW_CONTOURS = False\n",
    "avaiable_types = list(templates_dict.keys())\n",
    "avaiable_templates = set(orange_signs_list)\n",
    "\n",
    "def addBlur(img):\n",
    "    '''\n",
    "    Adds a blur to the image.\n",
    "    :param img: Image to be blurred.\n",
    "    :return: Blurred image.\n",
    "    '''\n",
    "    kernel = np.ones((5,5), np.float32)/25  #Blur kernel with a size of 5x5 and a factor of 1/25 (default)\n",
    "    img = cv2.filter2D(img, -1, kernel)     #Blur image using kernel\n",
    "    return img\n",
    "\n",
    "def checkIntervals(a, b, c, d):\n",
    "    '''\n",
    "    Checks if a < b and c < d.\n",
    "    :param a: First interval start.\n",
    "    :param b: First interval end.\n",
    "    :param c: Second interval start.\n",
    "    :param d: Second interval end.\n",
    "    :return: True if b-a and d-c are greater than 0, False otherwise.\n",
    "    '''\n",
    "    if a < b and c < d:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def chooseOffset(i, temp_w, temp_h):\n",
    "    '''\n",
    "    Depending on the quadrant we are drawing the template, we choose a different random offset.\n",
    "    :param i: Quadrant we are drawing the template.\n",
    "    :param temp_w: Template width.\n",
    "    :param temp_h: Template height.\n",
    "    :return: Random offset for the specific quadrant.\n",
    "    '''\n",
    "    if i == 0:\n",
    "        valid_intervals = checkIntervals(temp_w, WIDTH/2-temp_w, temp_h, HEIGHT/2-temp_h)\n",
    "        # Change these to change the position of first sign\n",
    "        if valid_intervals:\n",
    "            x_offset, y_offset= np.random.randint(temp_w, WIDTH/2-temp_w), np.random.randint(temp_h, HEIGHT/2-temp_h)     \n",
    "        else:\n",
    "            x_offset, y_offset= np.random.randint(5, temp_w), np.random.randint(5, temp_h)     \n",
    "    elif i == 1:\n",
    "        valid_intervals = checkIntervals(WIDTH/2+temp_w, WIDTH - temp_w, temp_h, HEIGHT/2-temp_h)\n",
    "        # Change these to change the position of second sign\n",
    "        if valid_intervals:\n",
    "            x_offset, y_offset= np.random.randint(WIDTH/2 + temp_w, WIDTH - temp_w), np.random.randint(temp_h, HEIGHT/2-temp_h)     \n",
    "        else:\n",
    "            x_offset, y_offset= np.random.randint(WIDTH/2, WIDTH/2 + temp_w), np.random.randint(10, temp_h)     \n",
    "    elif i == 2:\n",
    "        valid_intervals = checkIntervals(temp_w, WIDTH/2 - temp_w, HEIGHT/2+temp_h, HEIGHT - temp_h)\n",
    "        # Change these to change the position of third sign\n",
    "        if valid_intervals:\n",
    "            x_offset, y_offset= np.random.randint(temp_w, WIDTH/2 - temp_w), np.random.randint(HEIGHT/2 + temp_h, HEIGHT - temp_h)\n",
    "        else:\n",
    "            x_offset, y_offset= np.random.randint(10, temp_w), np.random.randint(HEIGHT/2 + 10, HEIGHT/2 + temp_h)\n",
    "    else:\n",
    "        valid_intervals = checkIntervals(WIDTH/2+temp_w, WIDTH - temp_w, HEIGHT/2+temp_h, HEIGHT - temp_h)\n",
    "        # Change these to change the position of fourth sign\n",
    "        if valid_intervals:\n",
    "            x_offset, y_offset= np.random.randint(WIDTH/2+temp_w, WIDTH - temp_h), np.random.randint(HEIGHT/2+temp_h, HEIGHT-temp_h)     \n",
    "        else:\n",
    "            x_offset, y_offset= np.random.randint(WIDTH/2+10, WIDTH/2 + temp_w), np.random.randint(HEIGHT/2+10, HEIGHT/2 + temp_h)\n",
    "\n",
    "    return x_offset, y_offset\n",
    "\n",
    "\n",
    "def addOffsetToContour(x_offset, y_offset, contours): \n",
    "    '''\n",
    "    Add offset to contours according to the position that we paste the sign template.\n",
    "    :param x_offset: X offset.\n",
    "    :param y_offset: Y offset.\n",
    "    :param contours: Contours to be offset.\n",
    "    :return: Offsetted contours.\n",
    "    '''\n",
    "    for contour in contours:\n",
    "        new_contour = contour + (x_offset, y_offset)\n",
    "    return new_contour\n",
    "\n",
    "\n",
    "def createPointsFromContours(contours):\n",
    "    '''\n",
    "    Create list of points_x and points_y from contours, to be used for create JSON object for annotations.\n",
    "    :param contours: Contours that gonna be used to extract values for points_x and points_y.\n",
    "    :return: Two lists: points_x, points_y\n",
    "    '''\n",
    "    points_x = []\n",
    "    points_y = []\n",
    "    for contour in contours:\n",
    "        for point in contour:\n",
    "            points_x.append(point[0])\n",
    "            points_y.append(point[1])\n",
    "    assert len(points_x) == len(points_y), \"Error: points_x and points_y have different length\"    \n",
    "    return points_x, points_y\n",
    "\n",
    "def selectTemplates(numberOfSigns):\n",
    "    '''\n",
    "    Selects the templates that are going to be used in the image.\n",
    "    Trying to create a constant distribution of type of signs.\n",
    "    :param numberOfSigns: Number of signs that are going to be used in the image.   \n",
    "    '''\n",
    "    global avaiable_templates, avaiable_types\n",
    "    chosen_list = []\n",
    "\n",
    "    while numberOfSigns > 0:\n",
    "        if len(avaiable_types) == 0:\n",
    "            avaiable_types = list(templates_dict.keys())\n",
    "        chosen_type = random.choice(avaiable_types) # Choose a random type of sign\n",
    "        avaiable_types.remove(chosen_type)          # Remove the chosen type from the list\n",
    "        # Get the list of templates of the chosen type\n",
    "        chosen_ones = [_ for _ in avaiable_templates if chosen_type+'_' in _]\n",
    "        #print(chosen_ones)\n",
    "        # Choose a random template from the chosen type\n",
    "        chosen = random.choice(chosen_ones) \n",
    "        chosen = chosen[:-4:]\n",
    "        # Add the chosen template to the list of chosen templates\n",
    "        chosen_list.append(chosen)\n",
    "        numberOfSigns -= 1\n",
    "\n",
    "        \n",
    "    return chosen_list\n",
    "\n",
    "\n",
    "\n",
    "def pasteTemplateIntoCocoImage(coco_img, templates_list, templates_dict):\n",
    "    '''\n",
    "    Uses arbitrary image `coco_img` and pastes beteen 1 and 4 templates of random signs into it.\n",
    "    :param coco_img: Image to be used to paste templates.\n",
    "    :param templates_list: List of templates with 3 sublists, each of then containnig signs of one these categories:\n",
    "        Daily: Signs that are the most for the day user.\n",
    "        Frequent: Signs that everybody have seen at least once.\n",
    "        Uncommom: Signs that probably aren't used often and fewer people know about them.\n",
    "    :param templates_dict: Dictionary with the templates and contours for each sign.\n",
    "    :return coco_img, countErrors, regions: Image with templates pasted, number of errors when pasting and regions to be used for annotations.\n",
    "    '''\n",
    "    countErrors = 0\n",
    "    numberOfSigns = np.random.randint(1, 5) # Random number of signs to be placed in the image [1, 4]\n",
    "    \n",
    "    ## Unpack templates_list\n",
    "    #daily_templates_list, frequent_templates_list, uncommom_templates_list = templates_list[0] \n",
    "    \n",
    "    chosen_list = [] # List to save 1 to 4 signs templates to paste in the image\n",
    "    regions = [] # List to save object of regions to be used for annotations\n",
    "\n",
    "    chosen_list = selectTemplates(numberOfSigns)\n",
    "      \n",
    "    \n",
    "    for i, sign in enumerate(chosen_list):\n",
    "        sign_number = int(sign[-3::]) # select the number of this sign type\n",
    "        sign_type = sign[:-4:] # select the sign type\n",
    "\n",
    "        template_tuple = templates_dict[sign_type][sign_number] # get the template tuple for this sign\n",
    "        template = template_tuple[1] # get the template image\n",
    "        temp_h, temp_w, _ = template.shape # template height and width\n",
    "        # print(template.shape)\n",
    "        \n",
    "        ## Choose offset for the chosen sign template\n",
    "        x_offset, y_offset = chooseOffset(i, temp_w, temp_h) \n",
    "        \n",
    "        ## Using the offset to drag the image down and to the right    \n",
    "        y1, y2 = y_offset, y_offset + template.shape[0]\n",
    "        x1, x2 = x_offset, x_offset + template.shape[1]\n",
    "\n",
    "        alpha_s = template[:, :, 3] / 255.0 # get the alpha channel of the template\n",
    "        alpha_l = 1.0 - alpha_s  # alpha_l is the alpha of the background of the template\n",
    "        \n",
    "        for c in range(0, 3):\n",
    "            try:\n",
    "                ## paste the template on the image\n",
    "                coco_img[y1:y2, x1:x2, c] = (alpha_s * template[:, :, c] +\n",
    "                                    alpha_l * coco_img[y1:y2, x1:x2, c])   \n",
    "                ## Add offset to contours\n",
    "                template_countour = addOffsetToContour(x_offset, y_offset, template_tuple[2])  \n",
    "\n",
    "                if DRAW_CONTOURS:\n",
    "                    ## Draw contours on the images to check if positions are correct\n",
    "                    cv2.drawContours(coco_img, [template_countour], -1, (0, 255, 0), 3) \n",
    "                \n",
    "                ## Create points_x and points_y from contours for annotations    \n",
    "                points_x, points_y = createPointsFromContours(template_countour)    \n",
    "\n",
    "                annot_obj = {           # Create object to convert for JSON annotations\n",
    "                    \"shape_attributes\": {\n",
    "                        \"name\": \"polygon\",\n",
    "                        \"all_points_x\": points_x,\n",
    "                        \"all_points_y\": points_y\n",
    "                    },\n",
    "                    \"region_attributes\": \n",
    "                        {\n",
    "                            \"class\": sign_type\n",
    "                        }\n",
    "                }\n",
    "                regions.append(annot_obj) # Add JSON object to regions list\n",
    "            except:\n",
    "                countErrors+= 1 # if the template is bigger than the image, the program will crash\n",
    "                #print(f\"Error pasting template {sign_type}_{sign_number} into image\")\n",
    "                continue  \n",
    "        \n",
    "    return coco_img, countErrors, regions\n",
    "\n",
    "def createSampleImages(templates_dict, coco_imgs_list, templates_list, blurry):\n",
    "    '''\n",
    "    Creates artificial images with templates of signs pasted in them.\n",
    "    :param templates_dict: Dictionary with the templates and contours for each sign.\n",
    "    :param coco_imgs_list: List of images to be used to paste templates.\n",
    "    :param templates_list: List of templates with 3 sublists, each of then containnig signs of one these categories:\n",
    "        Daily: Signs that are the most for the day user.\n",
    "        Frequent: Signs that everybody have seen at least once.\n",
    "        Uncommom: Signs that probably aren't used often and fewer people know about them.\n",
    "    :param blurry: Boolean variable to determine if the images will be blurred or not.\n",
    "    :return: Object with annotations for all images generated.\n",
    "    '''\n",
    "    img_list = []\n",
    "    annot_obj = {}     # Create empty object to save annotations\n",
    "    totalErrors = 0    # Count Errors when trying to paste the template into the image\n",
    "\n",
    "\n",
    "    \n",
    "    for name in coco_imgs_list:\n",
    "        name = name[:-4:]       # remove .jpg\n",
    "        coco_img = cv2.imread(f'./coco_dataset/chosenImages/{name}.jpg')\n",
    "        ## Eliminate images with height greater than width (portraits)   \n",
    "        if(coco_img.shape[0] > coco_img.shape[1]):    \n",
    "            continue\n",
    "\n",
    "        ## Resize the image to 1600x900    \n",
    "        coco_img = cv2.resize(coco_img, (WIDTH, HEIGHT), interpolation = cv2.INTER_LINEAR) \n",
    "        \n",
    "        ## Paste templates into the image\n",
    "        coco_img, errors, regions_list = pasteTemplateIntoCocoImage(coco_img, templates_list, templates_dict) \n",
    "        totalErrors += errors   #Add errors to total errors      \n",
    "        \n",
    "        if blurry:\n",
    "            coco_img = addBlur(coco_img) #Add blur to the image\n",
    "            \n",
    "        if SAVE:\n",
    "            ## Save the image to the disk\n",
    "            cv2.imwrite(f'./simple_dataset/ArtificialSamples/{name}.jpg', coco_img) \n",
    "            ## Get the size of the image\n",
    "            img_size = str(os.stat(f'./simple_dataset/ArtificialSamples/{name}.jpg').st_size) \n",
    "            if ANNOTATIONS:\n",
    "        \n",
    "                img_annotation = { \n",
    "                    name+'.jpg'+img_size: \n",
    "                    {\n",
    "                        \"filename\": name+'.jpg',\n",
    "                        \"size\": img_size,\n",
    "                        \"regions\": regions_list,\n",
    "                        \"file_attributes\": {}\n",
    "                    }\n",
    "                }\n",
    "\n",
    "                annot_obj.update(img_annotation) # Add image annotation to the object\n",
    "                    \n",
    "        img_list.append(coco_img)\n",
    "                \n",
    "    return annot_obj, totalErrors\n",
    "\n",
    "    # cv2.imshow('Img', img_list[1])\n",
    "    # cv2.waitKey(0)\n",
    "\n",
    "# Split the list into sublists of 3000 elements each, otherwise the program has chances to crash\n",
    "sublists = [coco_imgs_list[x:x+100] for x in range(0, len(coco_imgs_list), 100)] \n",
    "errors_counter = 0\n",
    "for lst in sublists:\n",
    "    new_annotations, errors = createSampleImages(templates_dict, lst, templates_list, blurry=True)\n",
    "    errors_counter += errors\n",
    "    # Save the annotations to the disk\n",
    "    if SAVE:\n",
    "        annotations.update(new_annotations)\n",
    "print(f'Total errors: {errors_counter/3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b60ebf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "with open('./simple_dataset/new_annotations.json', 'w') as f:\n",
    "    json.dump(annotations, f, cls=NpEncoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fee70f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'R-19': 158,\n",
       " 'O-MP': 146,\n",
       " 'R-24a': 69,\n",
       " 'I-SA': 60,\n",
       " 'R-2': 43,\n",
       " 'R-6c': 20,\n",
       " 'R-15': 18,\n",
       " 'A-32b': 11,\n",
       " 'A-24': 10,\n",
       " 'A-32a': 4,\n",
       " 'R-5a': 4,\n",
       " 'R-3': 1,\n",
       " 'R-5b': 1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_and_count_classes(annotation):\n",
    "    classes = {}\n",
    "\n",
    "    for image in annotation.values():\n",
    "        for region in image[\"regions\"]:\n",
    "            classType = region[\"region_attributes\"][\"class\"]\n",
    "            classes[classType] = classes.get(classType, 0) + 1\n",
    "\n",
    "    return classes\n",
    "\n",
    "def get_ordered_classes(ann_path):\n",
    "    if not os.path.exists(ann_path):\n",
    "        assert False, \"Invalid annotation path\"\n",
    "\n",
    "    with open(ann_path, \"r\") as f:\n",
    "        _annotations = json.load(f)\n",
    "        \n",
    "    class_hist = extract_and_count_classes(_annotations)\n",
    "\n",
    "    return dict(sorted(class_hist.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "get_ordered_classes('./simple_dataset/annotations.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c976d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'R-19': 371,\n",
       " 'O-MP': 350,\n",
       " 'R-24a': 279,\n",
       " 'R-2': 250,\n",
       " 'R-15': 231,\n",
       " 'R-6c': 230,\n",
       " 'A-24': 223,\n",
       " 'A-32b': 221,\n",
       " 'A-32a': 217,\n",
       " 'R-3': 214,\n",
       " 'R-5b': 214,\n",
       " 'R-5a': 214,\n",
       " 'I-E': 213,\n",
       " 'I-SA': 60}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ordered_classes('./simple_dataset/new_annotations.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tensorflow25')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e58c90c1a3b05fc421967660c466c67c2fd21820cf1f6ba41a9eb258f9783709"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
